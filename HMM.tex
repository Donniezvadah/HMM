% Options for packages loaded elsewhere
% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  english,
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{5}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother



\ifLuaTeX
\usepackage[bidi=basic]{babel}
\else
\usepackage[bidi=default]{babel}
\fi
% get rid of language-specific shorthands (see #6817):
\let\LanguageShortHands\languageshorthands
\def\languageshorthands#1{}
\ifLuaTeX
  \usepackage[english]{selnolig} % disable illegal ligatures
\fi


\setlength{\emergencystretch}{3em} % prevent overfull lines

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}



 


\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdflang={en},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\author{}
\date{}
\begin{document}

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{3}
\tableofcontents
}

\section{Hidden Markov Models (HMMs): A Rigorous, Mathematically Heavy
Course}\label{hidden-markov-models-hmms-a-rigorous-mathematically-heavy-course}

This project is a \textbf{full, proof-oriented course on Hidden Markov
Models (HMMs)}, designed at the level of a serious graduate or early PhD
sequence.

The course emphasizes:

\begin{itemize}
\tightlist
\item
  \textbf{Probability theory and stochastic processes}
  (measure-theoretic where needed)
\item
  \textbf{Inference and algorithms} (forward--backward, Viterbi,
  EM/Baum--Welch) with \textbf{full derivations and proofs of
  correctness}
\item
  \textbf{Statistical theory} (consistency, asymptotic normality,
  identifiability)
\item
  \textbf{Advanced variants} (continuous-state, nonparametric, switching
  models)
\end{itemize}

The materials are organized into \textbf{12 sections (0--11)}. Each
section lives in its own directory, with a dedicated \texttt{README.md}
containing \textbf{detailed notes, theorems, and proof sketches}.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{Primary References (Used for Notation and
Examples)}\label{primary-references-used-for-notation-and-examples}

The exposition and notation lean heavily on:

\begin{itemize}
\tightlist
\item
  \textbf{Zucchini, MacDonald, Langrock} -- \emph{Hidden Markov Models
  for Time Series: An Introduction Using R} (2nd ed.).\\
  This is the \textbf{main guiding reference} for finite-state HMMs,
  likelihoods, algorithms, and many examples.
\item
  \textbf{Rabiner (1989)} -- \emph{A Tutorial on Hidden Markov Models
  and Selected Applications in Speech Recognition}.\\
  Classic algorithmic exposition (forward--backward, Viterbi,
  Baum--Welch).
\item
  \textbf{Cappé, Moulines, Rydén (2005)} -- \emph{Inference in Hidden
  Markov Models}.\\
  Deep, rigorous treatment of HMM inference and statistical properties.
\item
  \textbf{Douc, Moulines, Stoffer (2014)} -- \emph{Nonlinear Time
  Series: Theory, Methods and Applications}.\\
  Asymptotic theory and ergodic properties for dependent data, including
  HMMs.
\item
  \textbf{Murphy (2012)} -- \emph{Machine Learning: A Probabilistic
  Perspective}.\\
  Broad probabilistic graphical model framing.
\end{itemize}

Unless otherwise noted, \textbf{notation follows Zucchini et al.} where
feasible:

\begin{itemize}
\tightlist
\item
  Hidden state process: ((S\_t)\_\{t\ge 1\}), taking values in a finite
  set (\{1,\dots,K\})
\item
  Observation process: ((Y\_t)\_\{t\ge 1\})
\item
  Initial distribution: (\boldsymbol{\delta} =
  (\delta\emph{i)}\{i=1\}\^{}K)
\item
  Transition probability matrix: (\boldsymbol{\Gamma} =
  (\gamma\emph{\{ij\})}\{i,j=1\}\^{}K)
\item
  State-dependent (emission) densities or pmfs: (f\_i(\cdot)) for state
  (i)
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{Course Structure (Section
Index)}\label{course-structure-section-index}

Each bullet links to a folder containing a \textbf{section-specific
\texttt{README.md}}.

\begin{itemize}
\item
  \textbf{\href{section-0-mathematical-prerequisites/README.md}{0.
  Mathematical Prerequisites}}\\
  Measure-theoretic probability (light but precise), linear algebra and
  spectral theory for stochastic matrices, convexity and information
  geometry (KL divergence as a Bregman divergence).
\item
  \textbf{\href{section-1-markov-chains/README.md}{1. Markov Chains
  (Fully Rigorous)}}\\
  Finite-state Markov chains, Chapman--Kolmogorov equations, stationary
  and invariant distributions, reversibility, ergodic theory
  (irreducibility, aperiodicity, mixing times, spectral gaps), and
  non-homogeneous chains.
\item
  \textbf{\href{section-2-observation-models/README.md}{2. Observation
  Models and Emission Processes}}\\
  Graphical model formulation of HMMs, conditional independence
  structure, factorization of joint distributions,
  discrete/continuous/exponential-family emissions, and identifiability
  issues.
\item
  \textbf{\href{section-3-hmm-formal-definition/README.md}{3. Hidden
  Markov Models: Formal Definition}}\\
  Generative definition of HMMs, formal state and observation spaces,
  initial distribution, transition kernel, emission kernel, and rigorous
  derivation of the joint and marginal likelihood.
\item
  \textbf{\href{section-4-inference/README.md}{4. Inference in HMMs
  (Core Algorithms)}}\\
  Filtering (forward algorithm), smoothing (forward--backward), and
  decoding (Viterbi). Includes dynamic programming derivations,
  correctness proofs, and numerical stability considerations.
\item
  \textbf{\href{section-5-parameter-estimation/README.md}{5. Parameter
  Estimation}}\\
  Maximum likelihood estimation, EM/Baum--Welch algorithm (as coordinate
  ascent on an evidence lower bound), monotonicity and convergence
  guarantees, and identifiability theory.
\item
  \textbf{\href{section-6-asymptotics/README.md}{6. Asymptotics and
  Statistical Theory}}\\
  Consistency and asymptotic normality of MLE in ergodic HMMs,
  pseudo-true parameters under misspecification, Fisher information for
  dependent data.
\item
  \textbf{\href{section-7-advanced-hmms/README.md}{7. Non-Standard and
  Advanced HMMs}}\\
  Continuous-state HMMs (including linear Gaussian / Kalman models),
  nonparametric HMMs (e.g.~Dirichlet process HMMs), and switching
  state-space models.
\item
  \textbf{\href{section-8-computational-issues/README.md}{8.
  Computational and Numerical Issues}}\\
  Scaling and log-domain implementations, underflow and overflow
  analysis, complexity of exact inference (time and space), and
  approximate methods.
\item
  \textbf{\href{section-9-alternative-foundations/README.md}{9.
  Alternative Foundations}}\\
  Online and distribution-free perspectives, prediction with
  expert-advice style losses, regret bounds for HMM-like models,
  decision-theoretic framing via POMDPs.
\item
  \textbf{\href{section-10-applications/README.md}{10. Applications}}\\
  Full mathematical mapping of real applications: speech recognition,
  bioinformatics, finance, epidemiology, and more, always phrased as
  precise HMMs.
\item
  \textbf{\href{section-11-proof-problem-sets/README.md}{11. Proof-Based
  Problem Sets}}\\
  Collections of theorem-level exercises: proving algorithm correctness,
  constructing counterexamples, identifiability and stability proofs,
  and asymptotic bounds.
\end{itemize}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsection{How to Use This Course}\label{how-to-use-this-course}

\begin{itemize}
\tightlist
\item
  \textbf{Read Sections 0--1 carefully} if your background in
  probability or Markov chains is not fully measure-theoretic.\\
\item
  \textbf{Work through the proofs} in Sections 3--5; they are central to
  a deep understanding of HMMs. Zucchini et al.~provide many of the key
  derivations, which are expanded here.
\item
  \textbf{Use Sections 6--9} as advanced material or for a second pass
  when you care about asymptotics, nonparametric models, or
  decision-theoretic views.
\item
  \textbf{Attempt the problem sets in Section 11} as if they were exam
  or qualifying questions.
\end{itemize}

Roughly:

\begin{itemize}
\tightlist
\item
  \textbf{70\%} of the course is probability and inference theory
\item
  \textbf{20\%} is algorithms with correctness proofs
\item
  \textbf{10\%} is applications and modeling case studies
\end{itemize}




\end{document}
