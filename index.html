<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Hidden Markov Models — Rigorous Course</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <!-- Fonts -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap" rel="stylesheet" />

  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <header class="hero">
    <div class="hero-inner">
      <p class="hero-tag">Graduate / PhD-Level Course</p>
      <h1>Hidden Markov Models</h1>
      <p class="hero-sub">
        Measure-theoretic probability · Inference algorithms · Asymptotic theory
      </p>
      <p class="hero-sub small">
        Based on Zucchini, MacDonald &amp; Langrock, Capp&eacute;–Moulines–Ryd&eacute;n, Douc–Moulines–Stoffer, and Rabiner.
      </p>
      <a href="#structure" class="hero-cta">View Course Structure</a>
    </div>
  </header>

  <nav class="nav">
    <a href="#about">About</a>
    <a href="#structure">Sections</a>
    <a href="#notes">Lecture Notes</a>
    <a href="#resources">References</a>
  </nav>

  <main>
    <section id="about" class="section">
      <h2>Course Overview</h2>
      <p>
        This is a <strong>mathematically rigorous course on Hidden Markov Models (HMMs)</strong>,
        aimed at advanced graduate and early PhD students. The emphasis is on
        <strong>probability theory, inference, and statistical asymptotics</strong>, with algorithms
        such as forward–backward, Viterbi, and EM/Baum–Welch derived and proved from first principles.
      </p>
      <p>
        The written notes are organized into <strong>12 sections (0–11)</strong>, each of which has a
        dedicated <code>README.md</code> in this repository. This landing page gives you a quick
        visual map of those sections.
      </p>
    </section>

    <section id="structure" class="section glass">
      <h2>Course Sections</h2>
      <p class="section-intro">
        Each card below corresponds to a section in the course. The links point to the
        corresponding markdown notes in this repository.
      </p>

      <div class="section-grid">
        <a class="section-card" href="section-0-mathematical-prerequisites/README.md" target="_blank">
          <span class="section-label">Section 0</span>
          <h3>Mathematical Prerequisites</h3>
          <p>
            Measure-theoretic probability, stochastic matrices and spectral gap,
            convexity on the simplex, KL as a Bregman divergence.
          </p>
        </a>

        <a class="section-card" href="section-1-markov-chains/README.md" target="_blank">
          <span class="section-label">Section 1</span>
          <h3>Markov Chains (Rigorous)</h3>
          <p>
            Homogeneous finite-state chains, ergodic theory, stationary distributions,
            reversibility, mixing times, spectral analysis and coupling.
          </p>
        </a>

        <a class="section-card" href="section-2-observation-models/README.md" target="_blank">
          <span class="section-label">Section 2</span>
          <h3>Observation Models</h3>
          <p>
            Graphical model structure, factorization, discrete and continuous emissions,
            exponential families, identifiability of emission processes.
          </p>
        </a>

        <a class="section-card" href="section-3-hmm-formal-definition/README.md" target="_blank">
          <span class="section-label">Section 3</span>
          <h3>Formal HMM Definition</h3>
          <p>
            Generative definition of finite-state HMMs, joint and marginal likelihoods,
            matrix-product representation in Zucchini notation.
          </p>
        </a>

        <a class="section-card" href="section-4-inference/README.md" target="_blank">
          <span class="section-label">Section 4</span>
          <h3>Inference Algorithms</h3>
          <p>
            Forward filtering, forward–backward smoothing, Viterbi decoding,
            dynamic programming proofs and numerically stable implementations.
          </p>
        </a>

        <a class="section-card" href="section-5-parameter-estimation/README.md" target="_blank">
          <span class="section-label">Section 5</span>
          <h3>Parameter Estimation</h3>
          <p>
            Maximum likelihood, EM/Baum–Welch as coordinate ascent on an ELBO,
            monotonicity, convergence, and identifiability issues.
          </p>
        </a>

        <a class="section-card" href="section-6-asymptotics/README.md" target="_blank">
          <span class="section-label">Section 6</span>
          <h3>Asymptotic Theory</h3>
          <p>
            Consistency of the MLE, pseudo-true parameters under misspecification,
            Fisher information and asymptotic normality for dependent data.
          </p>
        </a>

        <a class="section-card" href="section-7-advanced-hmms/README.md" target="_blank">
          <span class="section-label">Section 7</span>
          <h3>Advanced HMMs</h3>
          <p>
            Continuous-state models, Kalman filtering as a special case,
            nonparametric and infinite-state HMMs, switching state-space models.
          </p>
        </a>

        <a class="section-card" href="section-8-computational-issues/README.md" target="_blank">
          <span class="section-label">Section 8</span>
          <h3>Computational Issues</h3>
          <p>
            Scaling and log-domain implementations, underflow analysis,
            complexity and approximate inference strategies.
          </p>
        </a>

        <a class="section-card" href="section-9-alternative-foundations/README.md" target="_blank">
          <span class="section-label">Section 9</span>
          <h3>Alternative Foundations</h3>
          <p>
            Online prediction and regret, expert-advice style bounds,
            decision-theoretic framing and POMDP connections.
          </p>
        </a>

        <a class="section-card" href="section-10-applications/README.md" target="_blank">
          <span class="section-label">Section 10</span>
          <h3>Applications</h3>
          <p>
            Speech recognition, bioinformatics, finance, epidemiology, and other
            domains where HMMs provide state-based structure.
          </p>
        </a>

        <a class="section-card" href="section-11-proof-problem-sets/README.md" target="_blank">
          <span class="section-label">Section 11</span>
          <h3>Proof-Based Problem Sets</h3>
          <p>
            Exercises on Markov chains, inference algorithms, EM, identifiability,
            and asymptotic theory, suitable for graduate exams.
          </p>
        </a>
      </div>
    </section>

    <section id="notes" class="section">
      <h2>Lecture Notes</h2>
      <p>
        The primary lecture notes for this course are maintained as
        <strong>Markdown files</strong> in this repository:
      </p>
      <ul class="notes-list">
        <li>
          <code>HMM.md</code> — high-level overview and index of all sections.
        </li>
        <li>
          <code>section-*/README.md</code> — one detailed set of notes per section (0–11),
          written in a theorem/proof style with full derivations.
        </li>
      </ul>
      <p>
        For teaching, you can export each section to PDF or slides (e.g. via Pandoc or Quarto)
        while using this page as the animated course landing site.
      </p>
    </section>

    <section id="resources" class="section">
      <h2>Canonical References</h2>
      <p>
        The course leans heavily on the following texts and articles:
      </p>
      <ul class="resource-list">
        <li><strong>Zucchini, MacDonald, Langrock</strong>, <em>Hidden Markov Models for Time Series: An Introduction Using R</em>.</li>
        <li><strong>Rabiner (1989)</strong>, <em>A Tutorial on Hidden Markov Models and Selected Applications in Speech Recognition</em>.</li>
        <li><strong>Capp&eacute;, Moulines, Ryd&eacute;n</strong>, <em>Inference in Hidden Markov Models</em>.</li>
        <li><strong>Douc, Moulines, Stoffer</strong>, <em>Nonlinear Time Series: Theory, Methods and Applications</em>.</li>
        <li><strong>Murphy</strong>, <em>Machine Learning: A Probabilistic Perspective</em>.</li>
      </ul>
      <p>
        Zucchini et al. serve as the <strong>primary applied reference</strong> for notation and examples;
        the other works supply deeper theoretical results and broader probabilistic context.
      </p>
    </section>
  </main>

  <footer class="footer">
    <p>&copy; 2025 — Hidden Markov Models (Rigorous Course)</p>
  </footer>

  <script src="script.js"></script>
</body>
</html>
